{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e98acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/tfm/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# 필수 패키지 설치\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa2ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: I really love this product! IT works perfectly!\n",
      "예측 결과: {'label': 'POSITIVE', 'score': 0.9998819828033447}\n",
      "\n",
      "입력: This is the worst expreience I've ever had.\n",
      "예측 결과: {'label': 'NEGATIVE', 'score': 0.9997898936271667}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. HuggingFace 모델 불러와서 감정 분석하기 (pipeline 방식)\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1) 감정 분석 전용 pipeline 생성\n",
    "sentiment_classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# 2) 테스트 문장 입력\n",
    "texts = [\n",
    "    \"I really love this product! IT works perfectly!\",\n",
    "    \"This is the worst expreience I've ever had.\"\n",
    "]\n",
    "\n",
    "# 3) 결과 출력\n",
    "results = sentiment_classifier(texts)\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"입력: {text}\")\n",
    "    print(f\"예측 결과: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d11729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: I don't like this movie. It's boring.\n",
      "예측 감정: NEGATIVE\n",
      "확률: [[0.9994487166404724, 0.0005512956413440406]]\n"
     ]
    }
   ],
   "source": [
    "# 2) 모델 + 토크나이저 직접 불러와서 감정 분석하기 (로우레벨 방식)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import torch\n",
    "\n",
    "# 1) 모델 이름 지정\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# 2) 토크나이저 & 모델 로딩\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 3) 입력 문장\n",
    "text = \"I don't like this movie. It's boring.\"\n",
    "\n",
    "# 4) 토큰화 (문장을 텐서로 변환)\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 5) 모델 forward pass (logits 출력)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 6) softmax로 감정 확률 계산\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# 7) 레이블 매핑 ( 0=NEGATIVE, 1=POSITIVE )\n",
    "labels = ['NEGATIVE', 'POSITIVE']\n",
    "pred_label = labels[torch.argmax(probs)]\n",
    "\n",
    "print(f\"입력 문장: {text}\")\n",
    "print(f\"예측 감정: {pred_label}\")\n",
    "print(f\"확률: {probs.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6a6f62",
   "metadata": {},
   "source": [
    "AutoModelForSequenceClassification : HuggingFace Transformers 라이브러리에서, \"문장 단위 분류를 수행할 수 있도록 사전 정의된 모델 클래스를 자동으로 불러오는 역할\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34439338",
   "metadata": {},
   "source": [
    "### 데이터셋 불러와서 사전 학습된 모델로 감정 분류 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafeadb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 : it 's a charming and often affecting journey . \n",
      "예측 감정 : POSITIVE, 확률 : [[0.00011603943858062848, 0.9998838901519775]]\n",
      "\n",
      "문장 : unflinchingly bleak and desperate \n",
      "예측 감정 : NEGATIVE, 확률 : [[0.998969554901123, 0.0010304978350177407]]\n",
      "\n",
      "문장 : allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . \n",
      "예측 감정 : POSITIVE, 확률 : [[0.00035998859675601125, 0.9996399879455566]]\n",
      "\n",
      "문장 : the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \n",
      "예측 감정 : POSITIVE, 확률 : [[0.0003007006598636508, 0.9996993541717529]]\n",
      "\n",
      "문장 : it 's slow -- very , very slow . \n",
      "예측 감정 : NEGATIVE, 확률 : [[0.9996892213821411, 0.00031081135966815054]]\n",
      "\n",
      "문장 : although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . \n",
      "예측 감정 : POSITIVE, 확률 : [[0.0001709073258098215, 0.9998290538787842]]\n",
      "\n",
      "문장 : a sometimes tedious film . \n",
      "예측 감정 : NEGATIVE, 확률 : [[0.999504566192627, 0.0004954662872478366]]\n",
      "\n",
      "문장 : or doing last year 's taxes with your ex-wife . \n",
      "예측 감정 : NEGATIVE, 확률 : [[0.9917595982551575, 0.008240411058068275]]\n",
      "\n",
      "문장 : you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . \n",
      "예측 감정 : POSITIVE, 확률 : [[0.007328975014388561, 0.992671012878418]]\n",
      "\n",
      "문장 : in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey . \n",
      "예측 감정 : NEGATIVE, 확률 : [[0.9992507100105286, 0.0007492164149880409]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# 1) 감정 분석 모델 지정\n",
    "MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# 2) 데이터셋 로드 (SST-2, 영어 감정 분석 데이터)\n",
    "dataset = load_dataset(\"glue\",\"sst2\")\n",
    "test_data = dataset[\"validation\"] # 테스트용 데이터 split\n",
    "\n",
    "# 3) 토크나이저 & 모델 로딩\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 4) 테스트 데이터의 첫 10개 문장 예측 실행\n",
    "for i in range(10) :\n",
    "    text = test_data[i][\"sentence\"]\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim = -1 )\n",
    "    labels = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "    pred_label = labels[torch.argmax(probs)]\n",
    "\n",
    "    print(f\"문장 : {text}\")\n",
    "    print(f\"예측 감정 : {pred_label}, 확률 : {probs.tolist()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
